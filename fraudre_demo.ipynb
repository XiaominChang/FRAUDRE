{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model import MODEL\n",
    "from layers import *\n",
    "from utlis import *\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# # dataset and model dependent args\n",
    "# parser.add_argument('--data', type=str, default='amazon', help='The dataset name. [Amazon_demo, Yelp_demo, amazon,yelp]')\n",
    "# parser.add_argument('--batch-size', type=int, default=100, help='Batch size 1024 for yelp, 256 for amazon.')\n",
    "# parser.add_argument('--lr', type=float, default=0.1, help='Initial learning rate. [0.1 for amazon and 0.001 for yelp]')\n",
    "# parser.add_argument('--lambda_1', type=float, default=1e-4, help='Weight decay (L2 loss weight).')\n",
    "# parser.add_argument('--embed_dim', type=int, default=64, help='Node embedding size at the first layer.')\n",
    "# parser.add_argument('--num_epochs', type=int, default=61, help='Number of epochs.')\n",
    "# parser.add_argument('--test_epochs', type=int, default=10, help='Epoch interval to run test set.')\n",
    "# parser.add_argument('--seed', type=int, default=123, help='Random seed.')\n",
    "# parser.add_argument('--no_cuda', action='store_true', default=False, help='Disables CUDA training.')\n",
    "\n",
    "# if(torch.cuda.is_available()):\n",
    "# \tprint(\"cuda is available\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "# if(args.cuda):\n",
    "# \tprint(\"runing with GPU\")\n",
    "\n",
    "# print(f'run on {args.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: amazon\n",
      "Batch size: 100\n",
      "Learning rate: 0.1\n",
      "Weight decay: 0.0001\n",
      "Embedding dimension: 64\n",
      "Number of epochs: 61\n",
      "Test epochs: 10\n",
      "Random seed: 123\n",
      "CUDA enabled: False\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.data = 'amazon'  # The dataset name. [Amazon_demo, Yelp_demo, amazon, yelp]\n",
    "        self.batch_size = 100  # Batch size 1024 for yelp, 256 for amazon.\n",
    "        self.lr = 0.1  # Initial learning rate. [0.1 for amazon and 0.001 for yelp]\n",
    "        self.lambda_1 = 1e-4  # Weight decay (L2 loss weight).\n",
    "        self.embed_dim = 64  # Node embedding size at the first layer.\n",
    "        self.num_epochs = 61  # Number of epochs.\n",
    "        self.test_epochs = 10  # Epoch interval to run test set.\n",
    "        self.seed = 123  # Random seed.\n",
    "        self.no_cuda = False  # Disables CUDA training.\n",
    "\n",
    "args = Args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "\n",
    "# Access the arguments like this:\n",
    "print(f\"Dataset: {args.data}\")\n",
    "print(f\"Batch size: {args.batch_size}\")\n",
    "print(f\"Learning rate: {args.lr}\")\n",
    "print(f\"Weight decay: {args.lambda_1}\")\n",
    "print(f\"Embedding dimension: {args.embed_dim}\")\n",
    "print(f\"Number of epochs: {args.num_epochs}\")\n",
    "print(f\"Test epochs: {args.test_epochs}\")\n",
    "print(f\"Random seed: {args.seed}\")\n",
    "print(f\"CUDA enabled: {args.cuda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load topology, feature, and label\n",
    "homo, relation1, relation2, relation3, feat_data, labels = load_data(args.data)\n",
    "\n",
    "# set seed\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "# train_test split\n",
    "if args.data == 'yelp':\n",
    "\n",
    "\tindex = list(range(len(labels)))\n",
    "\tidx_train, idx_test, y_train, y_test = train_test_split(index, labels, stratify = labels, test_size = 0.80,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trandom_state = 2, shuffle = True)\n",
    "\n",
    "\t# set prior\n",
    "\tnum_1= len(np.where(y_train==1)[0])\n",
    "\tnum_2= len(np.where(y_train==0)[0])\n",
    "\tp0 = (num_1/(num_1+num_2))\n",
    "\tp1 = 1- p0\n",
    "\tprior = np.array([p1, p0])\n",
    "\n",
    "\tif args.cuda:\n",
    "\t\tprior = (torch.from_numpy(prior +1e-8)).cuda()\n",
    "\telse:\n",
    "\t\tprior = (torch.from_numpy(prior +1e-8))\n",
    "\n",
    "elif args.data == 'amazon':\n",
    "\n",
    "\t# 0-3304 are unlabeled nodes\n",
    "\tindex = list(range(3305, len(labels)))\n",
    "\tidx_train, idx_test, y_train, y_test = train_test_split(index, labels[3305:], stratify = labels[3305:],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttest_size = 0.90, random_state = 2, shuffle = True)\n",
    "\n",
    "\tnum_1 = len(np.where(y_train == 1)[0])\n",
    "\tnum_2 = len(np.where(y_train == 0)[0])\n",
    "\tp0 = (num_1 / (num_1 + num_2))\n",
    "\tp1 = 1 - p0\n",
    "\tprior = np.array([p1, p0])\n",
    "\tif args.cuda:\n",
    "\t\tprior = (torch.from_numpy(prior +1e-8)).cuda()\n",
    "\telse:\n",
    "\t\tprior = (torch.from_numpy(prior +1e-8))\n",
    "\t#prior = np.array([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model input\n",
    "features = nn.Embedding(feat_data.shape[0], feat_data.shape[1])\n",
    "feat_data = normalize(feat_data) \n",
    "features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad = False)\n",
    "if args.cuda:\n",
    "\tfeatures.cuda()\n",
    "\n",
    "# set input graph topology\n",
    "adj_lists = [relation1, relation2, relation3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "# the first neural network layer (ego-feature embedding module)\n",
    "mlp = MLP_(features, feat_data.shape[1], args.embed_dim, cuda = args.cuda)\n",
    "\n",
    "#first convolution layer\n",
    "intra1_1 = IntraAgg(cuda = args.cuda)\n",
    "intra1_2 = IntraAgg(cuda = args.cuda)\n",
    "intra1_3 = IntraAgg(cuda = args.cuda)\n",
    "agg1 = InterAgg(lambda nodes: mlp(nodes), args.embed_dim, adj_lists, [intra1_1, intra1_2, intra1_3], cuda = args.cuda)\n",
    "\n",
    "\n",
    "#second convolution layer\n",
    "intra2_1 = IntraAgg(cuda = args.cuda)\n",
    "intra2_2 = IntraAgg(cuda = args.cuda)\n",
    "intra2_3 = IntraAgg(cuda = args.cuda)\n",
    "\n",
    "#def __init__(self, features, embed_dim, adj_lists, intraggs, cuda = False):\n",
    "agg2 = InterAgg(lambda nodes: agg1(nodes), args.embed_dim*2, adj_lists, [intra2_1, intra2_2, intra2_3], cuda = args.cuda)\n",
    "gnn_model = MODEL(2, 2, args.embed_dim, agg2, prior)\n",
    "# gnn_model in one convolution layer\n",
    "#gnn_model = MODEL(1, 2, args.embed_dim, agg1, prior, cuda = args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, batch: 0\n",
      "Epoch: 0, batch: 1\n",
      "Epoch: 0, batch: 2\n",
      "Epoch: 0, batch: 3\n",
      "Epoch: 0, batch: 4\n",
      "Epoch: 0, batch: 5\n",
      "Epoch: 0, batch: 6\n",
      "Epoch: 0, batch: 7\n",
      "Epoch: 0, batch: 8\n",
      "Epoch: 0, loss: 0.14122858996600757, time: 2.466630458831787s\n",
      "GNN auc: 0.8921\n",
      "GNN precision: 0.9519\n",
      "GNN a_precision: 0.7695\n",
      "GNN Recall: 0.7357\n",
      "GNN f1: 0.8027\n",
      "Epoch: 1, batch: 0\n",
      "Epoch: 1, batch: 1\n",
      "Epoch: 1, batch: 2\n",
      "Epoch: 1, batch: 3\n",
      "Epoch: 1, batch: 4\n",
      "Epoch: 1, batch: 5\n",
      "Epoch: 1, batch: 6\n",
      "Epoch: 1, batch: 7\n",
      "Epoch: 1, batch: 8\n",
      "Epoch: 1, loss: 0.10129061832607324, time: 3.1055986881256104s\n",
      "Epoch: 2, batch: 0\n",
      "Epoch: 2, batch: 1\n",
      "Epoch: 2, batch: 2\n",
      "Epoch: 2, batch: 3\n",
      "Epoch: 2, batch: 4\n",
      "Epoch: 2, batch: 5\n",
      "Epoch: 2, batch: 6\n",
      "Epoch: 2, batch: 7\n",
      "Epoch: 2, batch: 8\n",
      "Epoch: 2, loss: 0.06852556800007704, time: 2.7235987186431885s\n",
      "Epoch: 3, batch: 0\n",
      "Epoch: 3, batch: 1\n",
      "Epoch: 3, batch: 2\n",
      "Epoch: 3, batch: 3\n",
      "Epoch: 3, batch: 4\n",
      "Epoch: 3, batch: 5\n",
      "Epoch: 3, batch: 6\n",
      "Epoch: 3, batch: 7\n",
      "Epoch: 3, batch: 8\n",
      "Epoch: 3, loss: 0.0315288906851169, time: 3.346250057220459s\n",
      "Epoch: 4, batch: 0\n",
      "Epoch: 4, batch: 1\n",
      "Epoch: 4, batch: 2\n",
      "Epoch: 4, batch: 3\n",
      "Epoch: 4, batch: 4\n",
      "Epoch: 4, batch: 5\n",
      "Epoch: 4, batch: 6\n",
      "Epoch: 4, batch: 7\n",
      "Epoch: 4, batch: 8\n",
      "Epoch: 4, loss: 0.019636383756974234, time: 4.2305748462677s\n",
      "Epoch: 5, batch: 0\n",
      "Epoch: 5, batch: 1\n",
      "Epoch: 5, batch: 2\n",
      "Epoch: 5, batch: 3\n",
      "Epoch: 5, batch: 4\n",
      "Epoch: 5, batch: 5\n",
      "Epoch: 5, batch: 6\n",
      "Epoch: 5, batch: 7\n",
      "Epoch: 5, batch: 8\n",
      "Epoch: 5, loss: 0.008890836932357059, time: 2.6663448810577393s\n",
      "Epoch: 6, batch: 0\n",
      "Epoch: 6, batch: 1\n",
      "Epoch: 6, batch: 2\n",
      "Epoch: 6, batch: 3\n",
      "Epoch: 6, batch: 4\n",
      "Epoch: 6, batch: 5\n",
      "Epoch: 6, batch: 6\n",
      "Epoch: 6, batch: 7\n",
      "Epoch: 6, batch: 8\n",
      "Epoch: 6, loss: 0.007744753969090513, time: 3.229126214981079s\n",
      "Epoch: 7, batch: 0\n",
      "Epoch: 7, batch: 1\n",
      "Epoch: 7, batch: 2\n",
      "Epoch: 7, batch: 3\n",
      "Epoch: 7, batch: 4\n",
      "Epoch: 7, batch: 5\n",
      "Epoch: 7, batch: 6\n",
      "Epoch: 7, batch: 7\n",
      "Epoch: 7, batch: 8\n",
      "Epoch: 7, loss: 0.022130425786153044, time: 2.6775190830230713s\n",
      "Epoch: 8, batch: 0\n",
      "Epoch: 8, batch: 1\n",
      "Epoch: 8, batch: 2\n",
      "Epoch: 8, batch: 3\n",
      "Epoch: 8, batch: 4\n",
      "Epoch: 8, batch: 5\n",
      "Epoch: 8, batch: 6\n",
      "Epoch: 8, batch: 7\n",
      "Epoch: 8, batch: 8\n",
      "Epoch: 8, loss: 0.02033086605448842, time: 2.7910797595977783s\n",
      "Epoch: 9, batch: 0\n",
      "Epoch: 9, batch: 1\n",
      "Epoch: 9, batch: 2\n",
      "Epoch: 9, batch: 3\n",
      "Epoch: 9, batch: 4\n",
      "Epoch: 9, batch: 5\n",
      "Epoch: 9, batch: 6\n",
      "Epoch: 9, batch: 7\n",
      "Epoch: 9, batch: 8\n",
      "Epoch: 9, loss: 0.007026535079043998, time: 2.28694748878479s\n",
      "Epoch: 10, batch: 0\n",
      "Epoch: 10, batch: 1\n",
      "Epoch: 10, batch: 2\n",
      "Epoch: 10, batch: 3\n",
      "Epoch: 10, batch: 4\n",
      "Epoch: 10, batch: 5\n",
      "Epoch: 10, batch: 6\n",
      "Epoch: 10, batch: 7\n",
      "Epoch: 10, batch: 8\n",
      "Epoch: 10, loss: 0.025374804915350824, time: 2.2917821407318115s\n",
      "GNN auc: 0.9263\n",
      "GNN precision: 0.8696\n",
      "GNN a_precision: 0.8287\n",
      "GNN Recall: 0.8847\n",
      "GNN f1: 0.8769\n",
      "Epoch: 11, batch: 0\n",
      "Epoch: 11, batch: 1\n",
      "Epoch: 11, batch: 2\n",
      "Epoch: 11, batch: 3\n",
      "Epoch: 11, batch: 4\n",
      "Epoch: 11, batch: 5\n",
      "Epoch: 11, batch: 6\n",
      "Epoch: 11, batch: 7\n",
      "Epoch: 11, batch: 8\n",
      "Epoch: 11, loss: 0.008675990054103263, time: 2.776066541671753s\n",
      "Epoch: 12, batch: 0\n",
      "Epoch: 12, batch: 1\n",
      "Epoch: 12, batch: 2\n",
      "Epoch: 12, batch: 3\n",
      "Epoch: 12, batch: 4\n",
      "Epoch: 12, batch: 5\n",
      "Epoch: 12, batch: 6\n",
      "Epoch: 12, batch: 7\n",
      "Epoch: 12, batch: 8\n",
      "Epoch: 12, loss: 0.03537230946151779, time: 2.6854782104492188s\n",
      "Epoch: 13, batch: 0\n",
      "Epoch: 13, batch: 1\n",
      "Epoch: 13, batch: 2\n",
      "Epoch: 13, batch: 3\n",
      "Epoch: 13, batch: 4\n",
      "Epoch: 13, batch: 5\n",
      "Epoch: 13, batch: 6\n",
      "Epoch: 13, batch: 7\n",
      "Epoch: 13, batch: 8\n",
      "Epoch: 13, loss: 0.030190880095731003, time: 2.5844597816467285s\n",
      "Epoch: 14, batch: 0\n",
      "Epoch: 14, batch: 1\n",
      "Epoch: 14, batch: 2\n",
      "Epoch: 14, batch: 3\n",
      "Epoch: 14, batch: 4\n",
      "Epoch: 14, batch: 5\n",
      "Epoch: 14, batch: 6\n",
      "Epoch: 14, batch: 7\n",
      "Epoch: 14, batch: 8\n",
      "Epoch: 14, loss: 0.040988130135768235, time: 2.9044997692108154s\n",
      "Epoch: 15, batch: 0\n",
      "Epoch: 15, batch: 1\n",
      "Epoch: 15, batch: 2\n",
      "Epoch: 15, batch: 3\n",
      "Epoch: 15, batch: 4\n",
      "Epoch: 15, batch: 5\n",
      "Epoch: 15, batch: 6\n",
      "Epoch: 15, batch: 7\n",
      "Epoch: 15, batch: 8\n",
      "Epoch: 15, loss: 0.033481521620442406, time: 2.5357186794281006s\n",
      "Epoch: 16, batch: 0\n",
      "Epoch: 16, batch: 1\n",
      "Epoch: 16, batch: 2\n",
      "Epoch: 16, batch: 3\n",
      "Epoch: 16, batch: 4\n",
      "Epoch: 16, batch: 5\n",
      "Epoch: 16, batch: 6\n",
      "Epoch: 16, batch: 7\n",
      "Epoch: 16, batch: 8\n",
      "Epoch: 16, loss: 0.01929278187835269, time: 3.399073362350464s\n",
      "Epoch: 17, batch: 0\n",
      "Epoch: 17, batch: 1\n",
      "Epoch: 17, batch: 2\n",
      "Epoch: 17, batch: 3\n",
      "Epoch: 17, batch: 4\n",
      "Epoch: 17, batch: 5\n",
      "Epoch: 17, batch: 6\n",
      "Epoch: 17, batch: 7\n",
      "Epoch: 17, batch: 8\n",
      "Epoch: 17, loss: 0.020698502729426114, time: 2.7035415172576904s\n",
      "Epoch: 18, batch: 0\n",
      "Epoch: 18, batch: 1\n",
      "Epoch: 18, batch: 2\n",
      "Epoch: 18, batch: 3\n",
      "Epoch: 18, batch: 4\n",
      "Epoch: 18, batch: 5\n",
      "Epoch: 18, batch: 6\n",
      "Epoch: 18, batch: 7\n",
      "Epoch: 18, batch: 8\n",
      "Epoch: 18, loss: 0.039229235422872065, time: 2.609023332595825s\n",
      "Epoch: 19, batch: 0\n",
      "Epoch: 19, batch: 1\n",
      "Epoch: 19, batch: 2\n",
      "Epoch: 19, batch: 3\n",
      "Epoch: 19, batch: 4\n",
      "Epoch: 19, batch: 5\n",
      "Epoch: 19, batch: 6\n",
      "Epoch: 19, batch: 7\n",
      "Epoch: 19, batch: 8\n",
      "Epoch: 19, loss: 0.015464342021902068, time: 2.6995205879211426s\n",
      "Epoch: 20, batch: 0\n",
      "Epoch: 20, batch: 1\n",
      "Epoch: 20, batch: 2\n",
      "Epoch: 20, batch: 3\n",
      "Epoch: 20, batch: 4\n",
      "Epoch: 20, batch: 5\n",
      "Epoch: 20, batch: 6\n",
      "Epoch: 20, batch: 7\n",
      "Epoch: 20, batch: 8\n",
      "Epoch: 20, loss: 0.027219166707900828, time: 2.3380818367004395s\n",
      "GNN auc: 0.9311\n",
      "GNN precision: 0.6227\n",
      "GNN a_precision: 0.8391\n",
      "GNN Recall: 0.8148\n",
      "GNN f1: 0.6213\n",
      "Epoch: 21, batch: 0\n",
      "Epoch: 21, batch: 1\n",
      "Epoch: 21, batch: 2\n",
      "Epoch: 21, batch: 3\n",
      "Epoch: 21, batch: 4\n",
      "Epoch: 21, batch: 5\n",
      "Epoch: 21, batch: 6\n",
      "Epoch: 21, batch: 7\n",
      "Epoch: 21, batch: 8\n",
      "Epoch: 21, loss: 0.0337316816190692, time: 2.513094902038574s\n",
      "Epoch: 22, batch: 0\n",
      "Epoch: 22, batch: 1\n",
      "Epoch: 22, batch: 2\n",
      "Epoch: 22, batch: 3\n",
      "Epoch: 22, batch: 4\n",
      "Epoch: 22, batch: 5\n",
      "Epoch: 22, batch: 6\n",
      "Epoch: 22, batch: 7\n",
      "Epoch: 22, batch: 8\n",
      "Epoch: 22, loss: 0.024185874673416277, time: 2.318484306335449s\n",
      "Epoch: 23, batch: 0\n",
      "Epoch: 23, batch: 1\n",
      "Epoch: 23, batch: 2\n",
      "Epoch: 23, batch: 3\n",
      "Epoch: 23, batch: 4\n",
      "Epoch: 23, batch: 5\n",
      "Epoch: 23, batch: 6\n",
      "Epoch: 23, batch: 7\n",
      "Epoch: 23, batch: 8\n",
      "Epoch: 23, loss: 0.10447335524201498, time: 2.8649089336395264s\n",
      "Epoch: 24, batch: 0\n",
      "Epoch: 24, batch: 1\n",
      "Epoch: 24, batch: 2\n",
      "Epoch: 24, batch: 3\n",
      "Epoch: 24, batch: 4\n",
      "Epoch: 24, batch: 5\n",
      "Epoch: 24, batch: 6\n",
      "Epoch: 24, batch: 7\n",
      "Epoch: 24, batch: 8\n",
      "Epoch: 24, loss: 0.03756999115040698, time: 2.8946056365966797s\n",
      "Epoch: 25, batch: 0\n",
      "Epoch: 25, batch: 1\n",
      "Epoch: 25, batch: 2\n",
      "Epoch: 25, batch: 3\n",
      "Epoch: 25, batch: 4\n",
      "Epoch: 25, batch: 5\n",
      "Epoch: 25, batch: 6\n",
      "Epoch: 25, batch: 7\n",
      "Epoch: 25, batch: 8\n",
      "Epoch: 25, loss: 0.029617560268197465, time: 2.73089337348938s\n",
      "Epoch: 26, batch: 0\n",
      "Epoch: 26, batch: 1\n",
      "Epoch: 26, batch: 2\n",
      "Epoch: 26, batch: 3\n",
      "Epoch: 26, batch: 4\n",
      "Epoch: 26, batch: 5\n",
      "Epoch: 26, batch: 6\n",
      "Epoch: 26, batch: 7\n",
      "Epoch: 26, batch: 8\n",
      "Epoch: 26, loss: 0.006111110454983828, time: 2.430919647216797s\n",
      "Epoch: 27, batch: 0\n",
      "Epoch: 27, batch: 1\n",
      "Epoch: 27, batch: 2\n",
      "Epoch: 27, batch: 3\n",
      "Epoch: 27, batch: 4\n",
      "Epoch: 27, batch: 5\n",
      "Epoch: 27, batch: 6\n",
      "Epoch: 27, batch: 7\n",
      "Epoch: 27, batch: 8\n",
      "Epoch: 27, loss: 0.01262578407224251, time: 2.673862934112549s\n",
      "Epoch: 28, batch: 0\n",
      "Epoch: 28, batch: 1\n",
      "Epoch: 28, batch: 2\n",
      "Epoch: 28, batch: 3\n",
      "Epoch: 28, batch: 4\n",
      "Epoch: 28, batch: 5\n",
      "Epoch: 28, batch: 6\n",
      "Epoch: 28, batch: 7\n",
      "Epoch: 28, batch: 8\n",
      "Epoch: 28, loss: 0.009307536299816496, time: 3.1999409198760986s\n",
      "Epoch: 29, batch: 0\n",
      "Epoch: 29, batch: 1\n",
      "Epoch: 29, batch: 2\n",
      "Epoch: 29, batch: 3\n",
      "Epoch: 29, batch: 4\n",
      "Epoch: 29, batch: 5\n",
      "Epoch: 29, batch: 6\n",
      "Epoch: 29, batch: 7\n",
      "Epoch: 29, batch: 8\n",
      "Epoch: 29, loss: 0.05136421833875329, time: 2.7073616981506348s\n",
      "Epoch: 30, batch: 0\n",
      "Epoch: 30, batch: 1\n",
      "Epoch: 30, batch: 2\n",
      "Epoch: 30, batch: 3\n",
      "Epoch: 30, batch: 4\n",
      "Epoch: 30, batch: 5\n",
      "Epoch: 30, batch: 6\n",
      "Epoch: 30, batch: 7\n",
      "Epoch: 30, batch: 8\n",
      "Epoch: 30, loss: 0.019772945319649692, time: 2.6528005599975586s\n",
      "GNN auc: 0.9265\n",
      "GNN precision: 0.8426\n",
      "GNN a_precision: 0.8288\n",
      "GNN Recall: 0.8831\n",
      "GNN f1: 0.8613\n",
      "Epoch: 31, batch: 0\n",
      "Epoch: 31, batch: 1\n",
      "Epoch: 31, batch: 2\n",
      "Epoch: 31, batch: 3\n",
      "Epoch: 31, batch: 4\n",
      "Epoch: 31, batch: 5\n",
      "Epoch: 31, batch: 6\n",
      "Epoch: 31, batch: 7\n",
      "Epoch: 31, batch: 8\n",
      "Epoch: 31, loss: 0.02012935868672823, time: 3.2425663471221924s\n",
      "Epoch: 32, batch: 0\n",
      "Epoch: 32, batch: 1\n",
      "Epoch: 32, batch: 2\n",
      "Epoch: 32, batch: 3\n",
      "Epoch: 32, batch: 4\n",
      "Epoch: 32, batch: 5\n",
      "Epoch: 32, batch: 6\n",
      "Epoch: 32, batch: 7\n",
      "Epoch: 32, batch: 8\n",
      "Epoch: 32, loss: 0.028406803773612037, time: 2.406905174255371s\n",
      "Epoch: 33, batch: 0\n",
      "Epoch: 33, batch: 1\n",
      "Epoch: 33, batch: 2\n",
      "Epoch: 33, batch: 3\n",
      "Epoch: 33, batch: 4\n",
      "Epoch: 33, batch: 5\n",
      "Epoch: 33, batch: 6\n",
      "Epoch: 33, batch: 7\n",
      "Epoch: 33, batch: 8\n",
      "Epoch: 33, loss: 0.003346068421844925, time: 2.6900124549865723s\n",
      "Epoch: 34, batch: 0\n",
      "Epoch: 34, batch: 1\n",
      "Epoch: 34, batch: 2\n",
      "Epoch: 34, batch: 3\n",
      "Epoch: 34, batch: 4\n",
      "Epoch: 34, batch: 5\n",
      "Epoch: 34, batch: 6\n",
      "Epoch: 34, batch: 7\n",
      "Epoch: 34, batch: 8\n",
      "Epoch: 34, loss: 0.052867666498621985, time: 2.8996670246124268s\n",
      "Epoch: 35, batch: 0\n",
      "Epoch: 35, batch: 1\n",
      "Epoch: 35, batch: 2\n",
      "Epoch: 35, batch: 3\n",
      "Epoch: 35, batch: 4\n",
      "Epoch: 35, batch: 5\n",
      "Epoch: 35, batch: 6\n",
      "Epoch: 35, batch: 7\n",
      "Epoch: 35, batch: 8\n",
      "Epoch: 35, loss: 0.021537764111062317, time: 2.61649489402771s\n",
      "Epoch: 36, batch: 0\n",
      "Epoch: 36, batch: 1\n",
      "Epoch: 36, batch: 2\n",
      "Epoch: 36, batch: 3\n",
      "Epoch: 36, batch: 4\n",
      "Epoch: 36, batch: 5\n",
      "Epoch: 36, batch: 6\n",
      "Epoch: 36, batch: 7\n",
      "Epoch: 36, batch: 8\n",
      "Epoch: 36, loss: 0.046364938588528776, time: 2.363983631134033s\n",
      "Epoch: 37, batch: 0\n",
      "Epoch: 37, batch: 1\n",
      "Epoch: 37, batch: 2\n",
      "Epoch: 37, batch: 3\n",
      "Epoch: 37, batch: 4\n",
      "Epoch: 37, batch: 5\n",
      "Epoch: 37, batch: 6\n",
      "Epoch: 37, batch: 7\n",
      "Epoch: 37, batch: 8\n",
      "Epoch: 37, loss: 0.010099806193655863, time: 2.7234082221984863s\n",
      "Epoch: 38, batch: 0\n",
      "Epoch: 38, batch: 1\n",
      "Epoch: 38, batch: 2\n",
      "Epoch: 38, batch: 3\n",
      "Epoch: 38, batch: 4\n",
      "Epoch: 38, batch: 5\n",
      "Epoch: 38, batch: 6\n",
      "Epoch: 38, batch: 7\n",
      "Epoch: 38, batch: 8\n",
      "Epoch: 38, loss: 0.016587672134730898, time: 2.551114559173584s\n",
      "Epoch: 39, batch: 0\n",
      "Epoch: 39, batch: 1\n",
      "Epoch: 39, batch: 2\n",
      "Epoch: 39, batch: 3\n",
      "Epoch: 39, batch: 4\n",
      "Epoch: 39, batch: 5\n",
      "Epoch: 39, batch: 6\n",
      "Epoch: 39, batch: 7\n",
      "Epoch: 39, batch: 8\n",
      "Epoch: 39, loss: 0.03335020325169348, time: 2.789578676223755s\n",
      "Epoch: 40, batch: 0\n",
      "Epoch: 40, batch: 1\n",
      "Epoch: 40, batch: 2\n",
      "Epoch: 40, batch: 3\n",
      "Epoch: 40, batch: 4\n",
      "Epoch: 40, batch: 5\n",
      "Epoch: 40, batch: 6\n",
      "Epoch: 40, batch: 7\n",
      "Epoch: 40, batch: 8\n",
      "Epoch: 40, loss: 0.004402703654747293, time: 2.8723740577697754s\n",
      "GNN auc: 0.9157\n",
      "GNN precision: 0.8920\n",
      "GNN a_precision: 0.8244\n",
      "GNN Recall: 0.8877\n",
      "GNN f1: 0.8899\n",
      "Epoch: 41, batch: 0\n",
      "Epoch: 41, batch: 1\n",
      "Epoch: 41, batch: 2\n",
      "Epoch: 41, batch: 3\n",
      "Epoch: 41, batch: 4\n",
      "Epoch: 41, batch: 5\n",
      "Epoch: 41, batch: 6\n",
      "Epoch: 41, batch: 7\n",
      "Epoch: 41, batch: 8\n",
      "Epoch: 41, loss: 0.016011068062271625, time: 2.4869730472564697s\n",
      "Epoch: 42, batch: 0\n",
      "Epoch: 42, batch: 1\n",
      "Epoch: 42, batch: 2\n",
      "Epoch: 42, batch: 3\n",
      "Epoch: 42, batch: 4\n",
      "Epoch: 42, batch: 5\n",
      "Epoch: 42, batch: 6\n",
      "Epoch: 42, batch: 7\n",
      "Epoch: 42, batch: 8\n",
      "Epoch: 42, loss: 0.01714844380144944, time: 2.514647960662842s\n",
      "Epoch: 43, batch: 0\n",
      "Epoch: 43, batch: 1\n",
      "Epoch: 43, batch: 2\n",
      "Epoch: 43, batch: 3\n",
      "Epoch: 43, batch: 4\n",
      "Epoch: 43, batch: 5\n",
      "Epoch: 43, batch: 6\n",
      "Epoch: 43, batch: 7\n",
      "Epoch: 43, batch: 8\n",
      "Epoch: 43, loss: 0.023024139656365537, time: 2.6962335109710693s\n",
      "Epoch: 44, batch: 0\n",
      "Epoch: 44, batch: 1\n",
      "Epoch: 44, batch: 2\n",
      "Epoch: 44, batch: 3\n",
      "Epoch: 44, batch: 4\n",
      "Epoch: 44, batch: 5\n",
      "Epoch: 44, batch: 6\n",
      "Epoch: 44, batch: 7\n",
      "Epoch: 44, batch: 8\n",
      "Epoch: 44, loss: 0.0219490126274996, time: 2.401435613632202s\n",
      "Epoch: 45, batch: 0\n",
      "Epoch: 45, batch: 1\n",
      "Epoch: 45, batch: 2\n",
      "Epoch: 45, batch: 3\n",
      "Epoch: 45, batch: 4\n",
      "Epoch: 45, batch: 5\n",
      "Epoch: 45, batch: 6\n",
      "Epoch: 45, batch: 7\n",
      "Epoch: 45, batch: 8\n",
      "Epoch: 45, loss: 0.028398748166569097, time: 2.6121041774749756s\n",
      "Epoch: 46, batch: 0\n",
      "Epoch: 46, batch: 1\n",
      "Epoch: 46, batch: 2\n",
      "Epoch: 46, batch: 3\n",
      "Epoch: 46, batch: 4\n",
      "Epoch: 46, batch: 5\n",
      "Epoch: 46, batch: 6\n",
      "Epoch: 46, batch: 7\n",
      "Epoch: 46, batch: 8\n",
      "Epoch: 46, loss: 0.02412607990271272, time: 2.5581791400909424s\n",
      "Epoch: 47, batch: 0\n",
      "Epoch: 47, batch: 1\n",
      "Epoch: 47, batch: 2\n",
      "Epoch: 47, batch: 3\n",
      "Epoch: 47, batch: 4\n",
      "Epoch: 47, batch: 5\n",
      "Epoch: 47, batch: 6\n",
      "Epoch: 47, batch: 7\n",
      "Epoch: 47, batch: 8\n",
      "Epoch: 47, loss: 0.008907178094674563, time: 2.4763824939727783s\n",
      "Epoch: 48, batch: 0\n",
      "Epoch: 48, batch: 1\n",
      "Epoch: 48, batch: 2\n",
      "Epoch: 48, batch: 3\n",
      "Epoch: 48, batch: 4\n",
      "Epoch: 48, batch: 5\n",
      "Epoch: 48, batch: 6\n",
      "Epoch: 48, batch: 7\n",
      "Epoch: 48, batch: 8\n",
      "Epoch: 48, loss: 0.001908347754228119, time: 2.7310078144073486s\n",
      "Epoch: 49, batch: 0\n",
      "Epoch: 49, batch: 1\n",
      "Epoch: 49, batch: 2\n",
      "Epoch: 49, batch: 3\n",
      "Epoch: 49, batch: 4\n",
      "Epoch: 49, batch: 5\n",
      "Epoch: 49, batch: 6\n",
      "Epoch: 49, batch: 7\n",
      "Epoch: 49, batch: 8\n",
      "Epoch: 49, loss: 0.019012226710741067, time: 2.7326700687408447s\n",
      "Epoch: 50, batch: 0\n",
      "Epoch: 50, batch: 1\n",
      "Epoch: 50, batch: 2\n",
      "Epoch: 50, batch: 3\n",
      "Epoch: 50, batch: 4\n",
      "Epoch: 50, batch: 5\n",
      "Epoch: 50, batch: 6\n",
      "Epoch: 50, batch: 7\n",
      "Epoch: 50, batch: 8\n",
      "Epoch: 50, loss: 0.0052825233615278674, time: 3.3157894611358643s\n",
      "GNN auc: 0.9290\n",
      "GNN precision: 0.7473\n",
      "GNN a_precision: 0.8282\n",
      "GNN Recall: 0.8647\n",
      "GNN f1: 0.7894\n",
      "Epoch: 51, batch: 0\n",
      "Epoch: 51, batch: 1\n",
      "Epoch: 51, batch: 2\n",
      "Epoch: 51, batch: 3\n",
      "Epoch: 51, batch: 4\n",
      "Epoch: 51, batch: 5\n",
      "Epoch: 51, batch: 6\n",
      "Epoch: 51, batch: 7\n",
      "Epoch: 51, batch: 8\n",
      "Epoch: 51, loss: 0.02215346406812127, time: 3.0317118167877197s\n",
      "Epoch: 52, batch: 0\n",
      "Epoch: 52, batch: 1\n",
      "Epoch: 52, batch: 2\n",
      "Epoch: 52, batch: 3\n",
      "Epoch: 52, batch: 4\n",
      "Epoch: 52, batch: 5\n",
      "Epoch: 52, batch: 6\n",
      "Epoch: 52, batch: 7\n",
      "Epoch: 52, batch: 8\n",
      "Epoch: 52, loss: 0.021968018079411795, time: 2.3586368560791016s\n",
      "Epoch: 53, batch: 0\n",
      "Epoch: 53, batch: 1\n",
      "Epoch: 53, batch: 2\n",
      "Epoch: 53, batch: 3\n",
      "Epoch: 53, batch: 4\n",
      "Epoch: 53, batch: 5\n",
      "Epoch: 53, batch: 6\n",
      "Epoch: 53, batch: 7\n",
      "Epoch: 53, batch: 8\n",
      "Epoch: 53, loss: 0.028568651328822043, time: 2.7326016426086426s\n",
      "Epoch: 54, batch: 0\n",
      "Epoch: 54, batch: 1\n",
      "Epoch: 54, batch: 2\n",
      "Epoch: 54, batch: 3\n",
      "Epoch: 54, batch: 4\n",
      "Epoch: 54, batch: 5\n",
      "Epoch: 54, batch: 6\n",
      "Epoch: 54, batch: 7\n",
      "Epoch: 54, batch: 8\n",
      "Epoch: 54, loss: 0.006296289636148634, time: 2.698655128479004s\n",
      "Epoch: 55, batch: 0\n",
      "Epoch: 55, batch: 1\n",
      "Epoch: 55, batch: 2\n",
      "Epoch: 55, batch: 3\n",
      "Epoch: 55, batch: 4\n",
      "Epoch: 55, batch: 5\n",
      "Epoch: 55, batch: 6\n",
      "Epoch: 55, batch: 7\n",
      "Epoch: 55, batch: 8\n",
      "Epoch: 55, loss: 0.016644345167130883, time: 2.8720459938049316s\n",
      "Epoch: 56, batch: 0\n",
      "Epoch: 56, batch: 1\n",
      "Epoch: 56, batch: 2\n",
      "Epoch: 56, batch: 3\n",
      "Epoch: 56, batch: 4\n",
      "Epoch: 56, batch: 5\n",
      "Epoch: 56, batch: 6\n",
      "Epoch: 56, batch: 7\n",
      "Epoch: 56, batch: 8\n",
      "Epoch: 56, loss: 0.022645372359388325, time: 2.822061538696289s\n",
      "Epoch: 57, batch: 0\n",
      "Epoch: 57, batch: 1\n",
      "Epoch: 57, batch: 2\n",
      "Epoch: 57, batch: 3\n",
      "Epoch: 57, batch: 4\n",
      "Epoch: 57, batch: 5\n",
      "Epoch: 57, batch: 6\n",
      "Epoch: 57, batch: 7\n",
      "Epoch: 57, batch: 8\n",
      "Epoch: 57, loss: 0.004659589474714632, time: 2.953425884246826s\n",
      "Epoch: 58, batch: 0\n",
      "Epoch: 58, batch: 1\n",
      "Epoch: 58, batch: 2\n",
      "Epoch: 58, batch: 3\n",
      "Epoch: 58, batch: 4\n",
      "Epoch: 58, batch: 5\n",
      "Epoch: 58, batch: 6\n",
      "Epoch: 58, batch: 7\n",
      "Epoch: 58, batch: 8\n",
      "Epoch: 58, loss: 0.029608180165336742, time: 3.4718263149261475s\n",
      "Epoch: 59, batch: 0\n",
      "Epoch: 59, batch: 1\n",
      "Epoch: 59, batch: 2\n",
      "Epoch: 59, batch: 3\n",
      "Epoch: 59, batch: 4\n",
      "Epoch: 59, batch: 5\n",
      "Epoch: 59, batch: 6\n",
      "Epoch: 59, batch: 7\n",
      "Epoch: 59, batch: 8\n",
      "Epoch: 59, loss: 0.05356565761947036, time: 2.9967870712280273s\n",
      "Epoch: 60, batch: 0\n",
      "Epoch: 60, batch: 1\n",
      "Epoch: 60, batch: 2\n",
      "Epoch: 60, batch: 3\n",
      "Epoch: 60, batch: 4\n",
      "Epoch: 60, batch: 5\n",
      "Epoch: 60, batch: 6\n",
      "Epoch: 60, batch: 7\n",
      "Epoch: 60, batch: 8\n",
      "Epoch: 60, loss: 0.03651413992400927, time: 2.3395421504974365s\n",
      "GNN auc: 0.9280\n",
      "GNN precision: 0.8836\n",
      "GNN a_precision: 0.8317\n",
      "GNN Recall: 0.8873\n",
      "GNN f1: 0.8854\n",
      "The training time per epoch\n",
      "2.7540428130353085\n"
     ]
    }
   ],
   "source": [
    "if args.cuda:\n",
    "\tgnn_model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, gnn_model.parameters()), lr=args.lr, weight_decay=args.lambda_1)\n",
    "performance_log = []\n",
    "\n",
    "# train the model\n",
    "\n",
    "overall_time = 0\n",
    "for epoch in range(args.num_epochs):\n",
    "\n",
    "\t# gnn_model.train()\n",
    "\t# shuffle\n",
    "\trandom.shuffle(idx_train)\n",
    "\tnum_batches = int(len(idx_train) / args.batch_size) +1\n",
    "\n",
    "\tloss = 0.0\n",
    "\tepoch_time = 0\n",
    "\n",
    "\t#mini-batch training\n",
    "\tfor batch in range(num_batches):\n",
    "\n",
    "\t\tprint(f'Epoch: {epoch}, batch: {batch}')\n",
    "\n",
    "\t\ti_start = batch * args.batch_size\n",
    "\t\ti_end = min((batch + 1) * args.batch_size, len(idx_train))\n",
    "\n",
    "\t\tbatch_nodes = idx_train[i_start:i_end]\n",
    "\n",
    "\t\tbatch_label = labels[np.array(batch_nodes)]\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\tstart_time = time.time()\n",
    "\n",
    "\t\tif args.cuda:\n",
    "\t\t\tloss = gnn_model.loss(batch_nodes, Variable(torch.cuda.LongTensor(batch_label)))\n",
    "\t\telse:\n",
    "\t\t\tloss = gnn_model.loss(batch_nodes, Variable(torch.LongTensor(batch_label)))\n",
    "\n",
    "\t\tend_time = time.time()\n",
    "\n",
    "\t\tepoch_time += end_time - start_time\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tloss += loss.item()\n",
    "\n",
    "\tprint(f'Epoch: {epoch}, loss: {loss.item() / num_batches}, time: {epoch_time}s')\n",
    "\toverall_time += epoch_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN auc: 0.9280\n",
      "GNN precision: 0.8836\n",
      "GNN a_precision: 0.8317\n",
      "GNN Recall: 0.8873\n",
      "GNN f1: 0.8854\n",
      "The training time per epoch\n",
      "2.7540428130353085\n"
     ]
    }
   ],
   "source": [
    "#testing the model for every $test_epoch$ epoch\n",
    "if epoch % args.test_epochs == 0:\n",
    "\n",
    "\t\t#gnn_model.eval()\n",
    "\t\tauc, precision, a_p, recall, f1 = test_model(idx_test, y_test, gnn_model)\n",
    "\t\tperformance_log.append([auc, precision, a_p, recall, f1])\n",
    "\n",
    "print(\"The training time per epoch\")\n",
    "print(overall_time/args.num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
